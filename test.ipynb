{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IwILkW1F8FnJ"
   },
   "source": [
    "# Correction des typos\n",
    "\n",
    "Le but de ce projet est de corriger les fautes de frappes dans un texte sans recours à un dictionnaire, en utilisant un modèle de Markov caché (HMM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NuO2bOCE8FnR"
   },
   "source": [
    "## Chargement des données\n",
    "\n",
    "Données issues du *Manifeste de l'Unabomber* et artificiellement bruitées en mofifiant aléatoirement 10% ou 20% des lettres du corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from HMM import *\n",
    "from toolbox import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 states :\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "26 observations :\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "Sample example :\n",
      "[('a', 'a'), ('c', 'c'), ('v', 'c'), ('o', 'o'), ('u', 'u'), ('n', 'n'), ('t', 't')]\n"
     ]
    }
   ],
   "source": [
    "# Import data and separate datasets\n",
    "ERROR_RATE = 10  # 10% or 20%\n",
    "train_set, test_set = load_db(error_rate=ERROR_RATE)\n",
    "\n",
    "# Get states and observations sets\n",
    "states, observations = get_states_observations(train_set)\n",
    "print(\"{} states :\\n{}\".format(len(states), states))\n",
    "print(\"{} observations :\\n{}\".format(len(observations), observations))\n",
    "\n",
    "# Example from dataset\n",
    "print(\"\\nSample example :\\n{}\".format(train_set[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM forward d'ordre 1\n",
    "\n",
    "Essai de correction des typos par un HMM d'ordre 1 utilisant l'algorithme de Viterbi (forward)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM created with: \n",
      " * 26 states\n",
      " * 26 observations\n",
      "Training initial states probabilities... Done.\n",
      "Training transitions probabilities given states... Done.\n",
      "Training observations probabilities given states... Done.\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train HMM\n",
    "hmm = HMM(states, observations)\n",
    "hmm.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation sequence      : inferikrigy\n",
      "Real states sequence      : inferiority\n",
      "Predicted states sequence : inderiorigy\n"
     ]
    }
   ],
   "source": [
    "# Try HMM prediction on one sample\n",
    "SAMPLE = 11\n",
    "observation_sequence = [token[0] for token in test_set[SAMPLE]]\n",
    "states_sequence = [token[1] for token in test_set[SAMPLE]]\n",
    "\n",
    "predicted_states_sequence = hmm.predict([observation_sequence])\n",
    "\n",
    "print(\"Observation sequence      : {}\".format(\"\".join(observation_sequence)))\n",
    "print(\"Real states sequence      : {}\".format(\"\".join(states_sequence)))\n",
    "print(\"Predicted states sequence : {}\".format(\"\".join(predicted_states_sequence[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM score on test set\n",
      " * accuracy on full words : 74.55%\n",
      " * accuracy on letters    : 93.02%\n",
      "   > typos corrected      : 299 (4.08%)\n",
      "   > typos not corrected  : 446 (6.09%)\n",
      "   > typos added          : 65 (0.89%)\n",
      "\n",
      "Dummy score on test set\n",
      " * accuracy on full words : 62.89%\n",
      " * accuracy on letters    : 89.82%\n",
      "   > typos corrected      : 0 (0.00%)\n",
      "   > typos not corrected  : 745 (10.18%)\n",
      "   > typos added          : 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# observed letters and real letters\n",
    "obs_seq = [[token[0] for token in word] for word in test_set]\n",
    "real_seq = [[token[1] for token in word] for word in test_set]\n",
    "\n",
    "# HMM predicted letters\n",
    "pred_seq = [word for word in hmm.predict(obs_seq)]\n",
    "\n",
    "# compute errors stats\n",
    "hmm_char_res, hmm_word_res = compute_corrections_stats(obs_seq, real_seq, pred_seq)\n",
    "dummy_char_res, dummy_word_res = compute_corrections_stats(obs_seq, real_seq, obs_seq)\n",
    "\n",
    "# display main results\n",
    "print(\"HMM score on test set\")\n",
    "print(\" * accuracy on full words : {:.2f}%\".format(hmm_word_res['accuracy'] * 100))\n",
    "print(\" * accuracy on letters    : {:.2f}%\".format(hmm_char_res['accuracy'] * 100))\n",
    "print(\"   > typos corrected      : {} ({:.2f}%)\".format(hmm_char_res['typo_correction'], hmm_char_res['typo_correction'] / hmm_char_res['n_tokens'] * 100))\n",
    "print(\"   > typos not corrected  : {} ({:.2f}%)\".format(hmm_char_res['typo_nocorrection'], hmm_char_res['typo_nocorrection'] / hmm_char_res['n_tokens'] * 100))\n",
    "print(\"   > typos added          : {} ({:.2f}%)\".format(hmm_char_res['notypo_correction'], hmm_char_res['notypo_correction'] / hmm_char_res['n_tokens'] * 100))\n",
    "\n",
    "print(\"\\nDummy score on test set\")\n",
    "print(\" * accuracy on full words : {:.2f}%\".format(dummy_word_res['accuracy'] * 100))\n",
    "print(\" * accuracy on letters    : {:.2f}%\".format(dummy_char_res['accuracy'] * 100))\n",
    "print(\"   > typos corrected      : {} ({:.2f}%)\".format(dummy_char_res['typo_correction'], dummy_char_res['typo_correction'] / dummy_char_res['n_tokens'] * 100))\n",
    "print(\"   > typos not corrected  : {} ({:.2f}%)\".format(dummy_char_res['typo_nocorrection'], dummy_char_res['typo_nocorrection'] / dummy_char_res['n_tokens'] * 100))\n",
    "print(\"   > typos added          : {} ({:.2f}%)\".format(dummy_char_res['notypo_correction'], dummy_char_res['notypo_correction'] / dummy_char_res['n_tokens'] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YO0E0GvD8FnS"
   },
   "source": [
    "\n",
    "## HMM forward d'ordre 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TC4-tp2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
