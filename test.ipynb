{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IwILkW1F8FnJ"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Ce TP continue le TP précédent. Nous allons reprendre d'ailleurs les mêmes données et commencer la mise en oeuvre d'un modèle de Markov pour la prédiction des étiquettes: \n",
    "* une observation est une phrase, représentée comme une séquence de variables aléatoires, une par mot de la phrase\n",
    "* à cette observation est associée une séquence de variables aléatoires représentant les étiquettes, une par mot de la phrase également\n",
    "\n",
    "On suppose que la séquence d'observation (une phrase) est générée par un modèle de Markov caché. Les variables cachées sont donc les étiquettes à inférer. Nous allons commencer par écrire une classe python pour représenter le HMM. Cette classe évoluera au fil des TPs. \n",
    "\n",
    "Pour cela le code de départ suivant est donné. Afin d'initialiser un HMM, nous devons connaitre : \n",
    "- l'ensemble des états (ou *state_list*), dans notre cas l'ensemble des étiquettes grammaticales;\n",
    "- l'ensemble des observations (ou *observation_list*), dans notre cas l'ensemble des mots connus; tous les autres mots seront remplacés par l'élément spécial *UNK* qui fait partie de l'ensemble des observations. \n",
    "\n",
    "Enfin, en interne il est plus facile d'indexer les mots et et les états par des entiers. Ainsi à chaque éléments de respectivement l'ensemble des états et l'ensemble des observations, est associé un indice. Cela nous permet de tout traiter en \"matricielle\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NuO2bOCE8FnR"
   },
   "source": [
    "# Interface avec les données et apprentissage supervisé\n",
    "\n",
    "Ainsi pour initialiser un HMM, nous allons devoir lire les données (chose faîte lors du TP précédent): \n",
    "* écrire une fonction permettant d'initialiser le HMM à partir des données d'apprentissage\n",
    "* écrire une fonction *apprentissage_supervisé* qui permet d'estimer les paramètres \n",
    "\n",
    "Dans un premier temps, nous limiterons, comme lors du TP précédent, le vocabulaire aux mots apparaissant 10 fois ou plus. Les autres mots sont tous remplacés par la même forme *unk*\n",
    "\n",
    "Pour cela, le plan de travail peut être envisagé ainsi: \n",
    "* Lire les données puis générer un corpus de **train** (80%) puis de **test** (10%)\n",
    "* écrire une fonction qui créer à partir des données d'apprentissage (**train**), tous les comptes nécessaires pour l'estimation supervisée des paramètres du HMM\n",
    "* écrire 3 fonctions qui estimes les paramètres à partir des comptes, une fonction par distribution: observation, transition, état initial. \n",
    "* écrire une fonction qui reprend le tout et qui estime tous les paramètres du HMM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from HMM import *\n",
    "from toolbox import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and separate datasets\n",
    "\n",
    "import pickle\n",
    "corpus = pickle.load( open( \"../TP1/brown.save.p\", \"rb\" ) )\n",
    "\n",
    "train_set, valid_set, test_set = get_train_validation_test_sets(corpus, sets_ratio=(0.8, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM creating with: \n",
      " * 12 states\n",
      " * 7609 observations\n"
     ]
    }
   ],
   "source": [
    "# Initialize HMM\n",
    "\n",
    "states, observations = get_states_observations(train_set)\n",
    "\n",
    "hmm = HMM(states, observations)\n",
    "# p_transitions = hmm.transition_proba\n",
    "# p_emissions = hmm.observation_proba\n",
    "# p_states_start = hmm.initial_state_proba\n",
    "# hmm = HMM(states, observations, p_transitions, p_emissions, p_states_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initial states probabilities... Done.\n",
      "Training transitions probabilities given states... Done.\n",
      "Training observations probabilities given states... Done.\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train HMM\n",
    "hmm = HMM(states, observations)\n",
    "hmm.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation sequence      : ['Fire', 'Fighters', 'Local', '798', ',', 'which', 'is', 'sponsoring', 'the', 'toy', 'program', 'for', 'the', '12th', 'straight', 'year', ',', 'issued', 'a', 'call', 'for', 'San', 'Franciscans', 'to', 'turn', 'in', 'discarded', 'toys', ',', 'which', 'will', 'be', 'repaired', 'by', 'off-duty', 'firemen', '.']\n",
      "Real states sequence      : ['NOUN', 'NOUN', 'NOUN', 'NUM', '.', 'DET', 'VERB', 'VERB', 'DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', '.', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'PRT', 'VERB', 'PRT', 'VERB', 'NOUN', '.', 'DET', 'VERB', 'VERB', 'VERB', 'ADP', 'ADJ', 'NOUN', '.']\n",
      "Predicted states sequence : ['NOUN', 'VERB', 'ADJ', 'NOUN', '.', 'DET', 'VERB', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', '.', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'VERB', 'PRT', 'VERB', 'ADP', 'ADJ', 'NOUN', '.', 'DET', 'VERB', 'VERB', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.']\n"
     ]
    }
   ],
   "source": [
    "# Try HMM prediction on one sample\n",
    "SAMPLE = 2\n",
    "observation_sequence = [token[0] for token in valid_set[SAMPLE]]\n",
    "states_sequence = [token[1] for token in valid_set[SAMPLE]]\n",
    "\n",
    "predicted_states_sequence = hmm.predict(observation_sequence)\n",
    "\n",
    "print(\"Observation sequence      : {}\".format(observation_sequence))\n",
    "print(\"Real states sequence      : {}\".format(states_sequence))\n",
    "print(\"Predicted states sequence : {}\".format(predicted_states_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM score on test set :\n",
      " * 93.56% accuracy on words\n",
      " * 36.82% accuracy on full sentences\n",
      "HMM score on test set (ignoring UNK) :\n",
      " * 97.17% accuracy on words\n",
      " * 64.65% accuracy on full sentences\n"
     ]
    }
   ],
   "source": [
    "score_unk = hmm.score(test_set)\n",
    "score_nounk = hmm.score(test_set, ignore_unk=True)\n",
    "print(\"HMM score on test set :\\n * {:.2f}% accuracy on words\\n * {:.2f}% accuracy on full sentences\".format(score_unk[0]*100, score_unk[1]*100))\n",
    "print(\"HMM score on test set (ignoring UNK) :\\n * {:.2f}% accuracy on words\\n * {:.2f}% accuracy on full sentences\".format(score_nounk[0]*100, score_nounk[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YO0E0GvD8FnS"
   },
   "source": [
    "\n",
    "# Exercice : Algorithme de Viterbi\n",
    "\n",
    "La question qui se pose est comment calculer la meilleure séquence d'étiquettes pour une phrase donnée connaissant les paramètres du HMM. Par meilleure, on entend la séquence d'étiquettes (ou d'états) la plus probable connaissant la séquence d'obervation. \n",
    "\n",
    "Proposer et implémenter un algorithme répondant à cette question. Pour vous aider à démarrer, cet algorithme s'appelle Viterbi et regardez cette vidéo https://www.youtube.com/watch?v=RwwfUICZLsA, pour comprendre comment il opère. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TC4-tp2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
