{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from HMM import *\n",
    "from toolbox import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 states :\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "26 observations :\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "Sample example (observation, état) :\n",
      "[('a', 'a'), ('c', 'c'), ('v', 'c'), ('o', 'o'), ('u', 'u'), ('n', 'n'), ('t', 't')]\n"
     ]
    }
   ],
   "source": [
    "# Import and separate datasets\n",
    "ERROR_RATE = 10  # 10% or 20%\n",
    "train_set, test_set = load_db(error_rate=ERROR_RATE)\n",
    "X_train = [[token[0] for token in word] for word in train_set]\n",
    "y_train = [[token[1] for token in word] for word in train_set]\n",
    "X_test = [[token[0] for token in word] for word in test_set]\n",
    "y_test = [[token[1] for token in word] for word in test_set]\n",
    "\n",
    "# Get states and observations sets\n",
    "states, observations = get_observations_states(X_train, y_train)\n",
    "print(\"{} states :\\n{}\".format(len(states), states))\n",
    "print(\"{} observations :\\n{}\".format(len(observations), observations))\n",
    "\n",
    "# Example from dataset\n",
    "print(\"\\nSample example (observation, état) :\\n{}\".format(train_set[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to int and reshape to 1D data\n",
    "hmm1 = HMM(states, observations, verbose=False)\n",
    "X_train_id = [hmm1._convert_observations_sequence_to_index(sample) for sample in X_train]\n",
    "X_train_1D = np.atleast_2d(np.concatenate(X_train_id)).T\n",
    "X_train_lengths = [len(sample) for sample in X_train_id]\n",
    "\n",
    "X_test_id = [hmm1._convert_observations_sequence_to_index(sample) for sample in X_test]\n",
    "y_test_id = [hmm1._convert_observations_sequence_to_index(sample) for sample in y_test]\n",
    "X_test_1D = np.atleast_2d(np.concatenate(X_test_id)).T\n",
    "X_test_lengths = [len(sample) for sample in X_test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83974359, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.83974359, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.83974359, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.83974359, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.83974359,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.83974359, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.83974359, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.83974359, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.83974359, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.83974359,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.83974359, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.83974359, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.83974359, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.83974359, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.83974359,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.83974359, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.83974359, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.83974359, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.83974359, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.83974359,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.83974359, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.83974359, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.83974359, 0.00641026, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.83974359, 0.00641026,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.83974359,\n",
       "        0.00641026],\n",
       "       [0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.00641026, 0.00641026, 0.00641026, 0.00641026, 0.00641026,\n",
       "        0.83974359]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission0 = np.eye(26) + 0.2/26\n",
    "emission0 /= np.sum(emission0, axis=1)\n",
    "emission0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -466455.1652             +nan\n",
      "         2     -388599.9028      +77855.2624\n",
      "         3     -379193.9853       +9405.9175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialHMM(algorithm='viterbi', init_params='st', n_components=26,\n",
       "        n_iter=3, params='ste',\n",
       "        random_state=<mtrand.RandomState object at 0x7fde0bcc18b8>,\n",
       "        startprob_prior=1.0, tol=0.01, transmat_prior=1.0, verbose=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hmmlearn.hmm import GaussianHMM, MultinomialHMM, GMMHMM\n",
    "\n",
    "hmm_sk = MultinomialHMM(26, verbose=True, n_iter=3, init_params='st')\n",
    "hmm_sk.emissionprob_ = emission0\n",
    "hmm_sk.fit(X_train_1D, X_train_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM_sk score on test set\n",
      " * accuracy on full words : 63.42%\n",
      " * accuracy on letters    : 89.92%\n",
      "   > typos corrected      : 25 (0.34%)\n",
      "   > typos not corrected  : 720 (9.84%)\n",
      "   > typos added          : 18 (0.25%)\n",
      "\n",
      "Dummy score on test set\n",
      " * accuracy on full words : 62.89%\n",
      " * accuracy on letters    : 89.82%\n",
      "   > typos corrected      : 0 (0.00%)\n",
      "   > typos not corrected  : 745 (10.18%)\n",
      "   > typos added          : 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_sk = [hmm_sk.predict(np.atleast_2d(sample).T) for sample in X_test_id]\n",
    "y_test_pred = [hmm1._convert_states_sequence_to_string(sample) for sample in y_test_pred_sk]\n",
    "display_correction_stats(X_test, y_test, y_test_pred, name=\"HMM_sk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.949, 0.   , 0.001, 0.002, 0.01 , 0.001, 0.001, 0.002, 0.007,\n",
       "        0.001, 0.001, 0.001, 0.   , 0.001, 0.007, 0.001, 0.001, 0.002,\n",
       "        0.004, 0.003, 0.002, 0.   , 0.001, 0.   , 0.001, 0.001],\n",
       "       [0.01 , 0.79 , 0.008, 0.011, 0.012, 0.007, 0.006, 0.009, 0.006,\n",
       "        0.002, 0.003, 0.014, 0.006, 0.025, 0.009, 0.007, 0.001, 0.019,\n",
       "        0.022, 0.018, 0.002, 0.004, 0.005, 0.001, 0.004, 0.001],\n",
       "       [0.004, 0.002, 0.887, 0.006, 0.008, 0.005, 0.004, 0.004, 0.004,\n",
       "        0.001, 0.001, 0.006, 0.004, 0.01 , 0.004, 0.003, 0.   , 0.01 ,\n",
       "        0.012, 0.015, 0.001, 0.002, 0.003, 0.001, 0.003, 0.001],\n",
       "       [0.005, 0.001, 0.005, 0.894, 0.011, 0.004, 0.003, 0.003, 0.005,\n",
       "        0.001, 0.001, 0.005, 0.004, 0.008, 0.006, 0.002, 0.   , 0.008,\n",
       "        0.011, 0.013, 0.001, 0.002, 0.002, 0.001, 0.003, 0.001],\n",
       "       [0.003, 0.   , 0.   , 0.002, 0.969, 0.   , 0.   , 0.001, 0.004,\n",
       "        0.   , 0.001, 0.001, 0.   , 0.001, 0.004, 0.001, 0.   , 0.002,\n",
       "        0.002, 0.003, 0.001, 0.   , 0.001, 0.   , 0.001, 0.   ],\n",
       "       [0.006, 0.002, 0.006, 0.007, 0.01 , 0.864, 0.004, 0.005, 0.005,\n",
       "        0.001, 0.002, 0.01 , 0.004, 0.013, 0.007, 0.004, 0.   , 0.011,\n",
       "        0.012, 0.014, 0.002, 0.002, 0.004, 0.001, 0.003, 0.001],\n",
       "       [0.007, 0.002, 0.009, 0.009, 0.015, 0.006, 0.839, 0.004, 0.007,\n",
       "        0.001, 0.002, 0.008, 0.004, 0.011, 0.008, 0.004, 0.   , 0.011,\n",
       "        0.015, 0.023, 0.002, 0.002, 0.003, 0.001, 0.005, 0.001],\n",
       "       [0.003, 0.002, 0.001, 0.002, 0.007, 0.002, 0.003, 0.912, 0.011,\n",
       "        0.002, 0.001, 0.003, 0.001, 0.007, 0.008, 0.001, 0.   , 0.009,\n",
       "        0.007, 0.009, 0.002, 0.   , 0.002, 0.   , 0.003, 0.   ],\n",
       "       [0.005, 0.   , 0.001, 0.002, 0.009, 0.001, 0.001, 0.002, 0.952,\n",
       "        0.001, 0.001, 0.001, 0.   , 0.002, 0.006, 0.001, 0.   , 0.003,\n",
       "        0.004, 0.003, 0.002, 0.   , 0.002, 0.   , 0.001, 0.   ],\n",
       "       [0.022, 0.006, 0.009, 0.017, 0.044, 0.009, 0.008, 0.014, 0.03 ,\n",
       "        0.613, 0.006, 0.017, 0.008, 0.025, 0.032, 0.009, 0.001, 0.029,\n",
       "        0.033, 0.033, 0.01 , 0.003, 0.01 , 0.002, 0.01 , 0.002],\n",
       "       [0.016, 0.004, 0.008, 0.013, 0.033, 0.008, 0.007, 0.01 , 0.023,\n",
       "        0.003, 0.697, 0.015, 0.007, 0.019, 0.022, 0.007, 0.001, 0.022,\n",
       "        0.025, 0.031, 0.007, 0.003, 0.007, 0.001, 0.008, 0.002],\n",
       "       [0.004, 0.002, 0.003, 0.005, 0.008, 0.003, 0.002, 0.004, 0.004,\n",
       "        0.001, 0.002, 0.911, 0.003, 0.007, 0.005, 0.003, 0.   , 0.008,\n",
       "        0.008, 0.011, 0.001, 0.001, 0.002, 0.   , 0.003, 0.   ],\n",
       "       [0.005, 0.003, 0.006, 0.008, 0.01 , 0.005, 0.004, 0.005, 0.004,\n",
       "        0.001, 0.002, 0.009, 0.857, 0.015, 0.007, 0.005, 0.   , 0.012,\n",
       "        0.014, 0.014, 0.002, 0.002, 0.004, 0.001, 0.003, 0.001],\n",
       "       [0.002, 0.002, 0.003, 0.003, 0.006, 0.003, 0.001, 0.003, 0.002,\n",
       "        0.001, 0.001, 0.003, 0.003, 0.937, 0.003, 0.001, 0.   , 0.007,\n",
       "        0.006, 0.007, 0.001, 0.001, 0.002, 0.   , 0.001, 0.   ],\n",
       "       [0.005, 0.   , 0.001, 0.002, 0.008, 0.001, 0.001, 0.001, 0.005,\n",
       "        0.001, 0.001, 0.002, 0.   , 0.001, 0.956, 0.001, 0.   , 0.002,\n",
       "        0.004, 0.003, 0.002, 0.   , 0.001, 0.   , 0.001, 0.   ],\n",
       "       [0.01 , 0.003, 0.006, 0.007, 0.012, 0.005, 0.004, 0.005, 0.007,\n",
       "        0.001, 0.002, 0.009, 0.004, 0.012, 0.01 , 0.85 , 0.001, 0.01 ,\n",
       "        0.014, 0.013, 0.003, 0.002, 0.003, 0.001, 0.003, 0.001],\n",
       "       [0.042, 0.006, 0.013, 0.022, 0.062, 0.013, 0.011, 0.019, 0.039,\n",
       "        0.006, 0.008, 0.022, 0.01 , 0.028, 0.05 , 0.013, 0.469, 0.035,\n",
       "        0.045, 0.042, 0.011, 0.004, 0.012, 0.002, 0.012, 0.004],\n",
       "       [0.003, 0.001, 0.002, 0.003, 0.006, 0.002, 0.002, 0.002, 0.003,\n",
       "        0.001, 0.001, 0.004, 0.002, 0.005, 0.004, 0.002, 0.   , 0.935,\n",
       "        0.006, 0.007, 0.001, 0.001, 0.002, 0.   , 0.002, 0.   ],\n",
       "       [0.003, 0.001, 0.002, 0.003, 0.006, 0.002, 0.001, 0.002, 0.003,\n",
       "        0.001, 0.001, 0.003, 0.002, 0.005, 0.004, 0.002, 0.   , 0.005,\n",
       "        0.941, 0.007, 0.001, 0.001, 0.001, 0.   , 0.001, 0.   ],\n",
       "       [0.002, 0.001, 0.002, 0.002, 0.002, 0.002, 0.002, 0.001, 0.001,\n",
       "        0.   , 0.   , 0.002, 0.001, 0.003, 0.002, 0.002, 0.   , 0.004,\n",
       "        0.005, 0.961, 0.   , 0.001, 0.001, 0.   , 0.002, 0.   ],\n",
       "       [0.01 , 0.002, 0.002, 0.005, 0.019, 0.003, 0.002, 0.005, 0.012,\n",
       "        0.002, 0.002, 0.004, 0.002, 0.006, 0.015, 0.003, 0.   , 0.008,\n",
       "        0.009, 0.011, 0.87 , 0.   , 0.004, 0.   , 0.004, 0.001],\n",
       "       [0.005, 0.004, 0.01 , 0.014, 0.014, 0.009, 0.006, 0.005, 0.006,\n",
       "        0.002, 0.004, 0.012, 0.01 , 0.019, 0.007, 0.005, 0.   , 0.021,\n",
       "        0.023, 0.029, 0.002, 0.778, 0.005, 0.002, 0.006, 0.002],\n",
       "       [0.009, 0.003, 0.007, 0.009, 0.014, 0.007, 0.005, 0.006, 0.007,\n",
       "        0.002, 0.002, 0.011, 0.005, 0.018, 0.008, 0.005, 0.001, 0.017,\n",
       "        0.017, 0.017, 0.003, 0.002, 0.816, 0.001, 0.006, 0.001],\n",
       "       [0.026, 0.007, 0.017, 0.024, 0.047, 0.016, 0.011, 0.015, 0.028,\n",
       "        0.005, 0.006, 0.022, 0.014, 0.033, 0.038, 0.013, 0.001, 0.039,\n",
       "        0.045, 0.049, 0.007, 0.005, 0.011, 0.503, 0.013, 0.003],\n",
       "       [0.009, 0.002, 0.003, 0.007, 0.021, 0.003, 0.003, 0.005, 0.013,\n",
       "        0.002, 0.003, 0.007, 0.003, 0.007, 0.015, 0.003, 0.   , 0.01 ,\n",
       "        0.013, 0.017, 0.005, 0.001, 0.004, 0.001, 0.842, 0.001],\n",
       "       [0.033, 0.007, 0.012, 0.021, 0.063, 0.012, 0.01 , 0.015, 0.035,\n",
       "        0.005, 0.007, 0.021, 0.009, 0.027, 0.042, 0.012, 0.002, 0.033,\n",
       "        0.042, 0.043, 0.01 , 0.003, 0.012, 0.002, 0.011, 0.509]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(hmm_sk.emissionprob_, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st order HMM created with: \n",
      " * 26 states\n",
      " * 26 observations\n"
     ]
    }
   ],
   "source": [
    "# Initialize HMM\n",
    "hmm1 = HMM(states, observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- EXPECTATION\n",
      "EM LOOP: n_iter=0, delta=[0.05635637]\n",
      "-- MINIMIZATION\n",
      "-- EXPECTATION\n",
      "EM LOOP: n_iter=1, delta=[0.09544694]\n",
      "-- MINIMIZATION\n",
      "-- EXPECTATION\n",
      "EM LOOP: n_iter=2, delta=[0.14693602]\n",
      "-- MINIMIZATION\n",
      "-- EXPECTATION\n"
     ]
    }
   ],
   "source": [
    "# Train HMM\n",
    "hmm1.EM(X_train, max_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.exp(hmm1.observation_logproba), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM1 score on test set\n",
      " * accuracy on full words : 2.53%\n",
      " * accuracy on letters    : 7.69%\n",
      "   > typos corrected      : 56 (0.77%)\n",
      "   > typos not corrected  : 689 (9.41%)\n",
      "   > typos added          : 6068 (82.90%)\n",
      "\n",
      "Dummy score on test set\n",
      " * accuracy on full words : 62.89%\n",
      " * accuracy on letters    : 89.82%\n",
      "   > typos corrected      : 0 (0.00%)\n",
      "   > typos not corrected  : 745 (10.18%)\n",
      "   > typos added          : 0 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/.local/lib/python3.5/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = hmm1.predict(X_test)\n",
    "display_correction_stats(X_test, y_test, y_test_pred, name=\"HMM1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia example\n",
    "\n",
    "### our version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Healthy', 'Fever', 'Z_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = ['normal', 'cold', 'dizzy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st order HMM created with: \n",
      " * 3 states\n",
      " * 3 observations\n",
      "['Fever', 'Healthy', 'Z_end']\n",
      "['cold', 'dizzy', 'normal']\n"
     ]
    }
   ],
   "source": [
    "hmm_test = HMM(states, observations)  \n",
    "print(hmm_test.omega_Y)\n",
    "print(hmm_test.omega_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_test.transition_logproba = np.array([[0.59, 0.4, 0.01], [0.3, 0.69, 0.01], [0., 0., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_test.observation_logproba = np.array([[0.3, 0.6, 0.1], [0.4, 0.1, 0.5], [0.33, 0.33, 0.33]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_test.initial_state_logproba = np.array([0.4, 0.6, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = hmm_test.forward(observations_sequence=['normal', 'cold', 'dizzy'], decode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = hmm_test.backward(observations_sequence=['normal', 'cold', 'dizzy'], decode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04       0.03408    0.02812032]\n",
      " [0.3        0.0892     0.007518  ]\n",
      " [0.         0.001122   0.00077708]]\n",
      "[[0.0035016  0.0384     0.2       ]\n",
      " [0.021894   0.0412     0.03333333]\n",
      " [0.01249578 0.03707    0.11      ]]\n"
     ]
    }
   ],
   "source": [
    "print(alpha)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_bkw(observations, states, start_prob, trans_prob, emm_prob, end_st):\n",
    "    # forward part of the algorithm\n",
    "    fwd = []\n",
    "    f_prev = {}\n",
    "    for i, observation_i in enumerate(observations):\n",
    "        f_curr = {}\n",
    "        for st in states:\n",
    "            if i == 0:\n",
    "                # base case for the forward part\n",
    "                prev_f_sum = start_prob[st]\n",
    "            else:\n",
    "                prev_f_sum = sum(f_prev[k]*trans_prob[k][st] for k in states)\n",
    "\n",
    "            f_curr[st] = emm_prob[st][observation_i] * prev_f_sum\n",
    "\n",
    "        fwd.append(f_curr)\n",
    "        f_prev = f_curr\n",
    "\n",
    "    p_fwd = sum(f_curr[k] * trans_prob[k][end_st] for k in states)\n",
    "    print(fwd)\n",
    "\n",
    "    # backward part of the algorithm\n",
    "    bkw = []\n",
    "    b_prev = {}\n",
    "    for i, observation_i_plus in enumerate(reversed(observations[1:]+(None,))):\n",
    "        b_curr = {}\n",
    "        for st in states:\n",
    "            if i == 0:\n",
    "                # base case for backward part\n",
    "                b_curr[st] = trans_prob[st][end_st]\n",
    "            else:\n",
    "                b_curr[st] = sum(trans_prob[st][l] * emm_prob[l][observation_i_plus] * b_prev[l] for l in states)\n",
    "\n",
    "        bkw.insert(0,b_curr)\n",
    "        b_prev = b_curr\n",
    "    print(bkw)\n",
    "    p_bkw = sum(start_prob[l] * emm_prob[l][observations[0]] * b_curr[l] for l in states)\n",
    "\n",
    "    # merging the two parts\n",
    "    posterior = []\n",
    "    for i in range(len(observations)):\n",
    "        posterior.append({st: fwd[i][st] * bkw[i][st] / p_fwd for st in states})\n",
    "\n",
    "    assert p_fwd == p_bkw\n",
    "    return fwd, bkw, posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Healthy': 0.3, 'Fever': 0.04000000000000001}, {'Healthy': 0.0892, 'Fever': 0.03408}, {'Healthy': 0.007518, 'Fever': 0.028120319999999997}]\n",
      "[{'Healthy': 0.0010418399999999998, 'Fever': 0.00109578}, {'Healthy': 0.00249, 'Fever': 0.00394}, {'Healthy': 0.01, 'Fever': 0.01}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'Fever': 0.04000000000000001, 'Healthy': 0.3},\n",
       "  {'Fever': 0.03408, 'Healthy': 0.0892},\n",
       "  {'Fever': 0.028120319999999997, 'Healthy': 0.007518}],\n",
       " [{'Fever': 0.00109578, 'Healthy': 0.0010418399999999998},\n",
       "  {'Fever': 0.00394, 'Healthy': 0.00249},\n",
       "  {'Fever': 0.01, 'Healthy': 0.01}],\n",
       " [{'Fever': 0.1229889624426741, 'Healthy': 0.8770110375573259},\n",
       "  {'Fever': 0.3767719690490461, 'Healthy': 0.623228030950954},\n",
       "  {'Fever': 0.7890472951586943, 'Healthy': 0.2109527048413057}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = ('Healthy', 'Fever')\n",
    "end_state = 'E'\n",
    " \n",
    "observations = ('normal', 'cold', 'dizzy')\n",
    " \n",
    "start_probability = {'Healthy': 0.6, 'Fever': 0.4}\n",
    " \n",
    "transition_probability = {\n",
    "   'Healthy' : {'Healthy': 0.69, 'Fever': 0.3, 'E': 0.01},\n",
    "   'Fever' : {'Healthy': 0.4, 'Fever': 0.59, 'E': 0.01},\n",
    "   }\n",
    " \n",
    "emission_probability = {\n",
    "   'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "   'Fever' : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6},\n",
    "   }\n",
    "fwd_bkw(observations,\n",
    "                   states,\n",
    "                   start_probability,\n",
    "                   transition_probability,\n",
    "                   emission_probability,\n",
    "                   end_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04       0.03408    0.02812032]\n",
      " [0.3        0.0892     0.007518  ]\n",
      " [0.         0.001122   0.00077708]]\n",
      "[[0.0035016  0.0384     0.2       ]\n",
      " [0.021894   0.0412     0.03333333]\n",
      " [0.01249578 0.03707    0.11      ]]\n"
     ]
    }
   ],
   "source": [
    "print(alpha)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
